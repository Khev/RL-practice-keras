{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this copy, I just quickly wanted to re-run something "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kokeeffe/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "(episode, score, steps, T (mins)) = (1, -9.65469972510185e-06, 999, 0.009236482779184978)\n",
      "(episode, score, steps, T (mins)) = (2, -9.760071775175433e-06, 999, 0.007532517115275065)\n",
      "(episode, score, steps, T (mins)) = (3, -9.712949393052431e-06, 999, 0.006577452023824056)\n",
      "(episode, score, steps, T (mins)) = (4, -9.711547195116262e-06, 999, 0.006409001350402832)\n",
      "(episode, score, steps, T (mins)) = (5, -9.67299185230958e-06, 999, 0.006414302190144857)\n",
      "(episode, score, steps, T (mins)) = (6, -9.66448281117617e-06, 999, 0.006467767556508382)\n",
      "(episode, score, steps, T (mins)) = (7, -29.23287192696367, 999, 1.166856598854065)\n",
      "(episode, score, steps, T (mins)) = (8, -98.54582913448236, 999, 1.9316296497980754)\n",
      "(episode, score, steps, T (mins)) = (9, -85.71283748219837, 999, 1.9323854009310404)\n",
      "(episode, score, steps, T (mins)) = (10, -48.9486690367775, 999, 1.9656628489494323)\n",
      "(episode, score, steps, T (mins)) = (11, -54.10676952080289, 999, 2.142698649565379)\n",
      "(episode, score, steps, T (mins)) = (12, -83.31851906274275, 999, 2.34825363556544)\n",
      "(episode, score, steps, T (mins)) = (13, -91.89074217472496, 999, 2.1339807669321695)\n",
      "(episode, score, steps, T (mins)) = (14, -95.54842787913235, 999, 1.9749851822853088)\n",
      "(episode, score, steps, T (mins)) = (15, -96.85527318333142, 999, 1.9883365670839945)\n",
      "(episode, score, steps, T (mins)) = (16, -90.2782820327063, 999, 1.831399385134379)\n",
      "(episode, score, steps, T (mins)) = (17, -97.01118641391649, 999, 1.8722304503122966)\n",
      "(episode, score, steps, T (mins)) = (18, -97.87326974991817, 999, 2.20692583322525)\n",
      "(episode, score, steps, T (mins)) = (19, -99.08532283797442, 999, 2.1802953322728476)\n",
      "(episode, score, steps, T (mins)) = (20, -99.21782682786977, 999, 2.0556634147961934)\n",
      "(episode, score, steps, T (mins)) = (21, -98.92868263490564, 999, 1.9747608343760172)\n",
      "(episode, score, steps, T (mins)) = (22, -99.045056856327, 999, 1.735020633538564)\n",
      "(episode, score, steps, T (mins)) = (23, -99.25584272347044, 999, 1.7328673680623372)\n",
      "(episode, score, steps, T (mins)) = (24, -99.36756607306717, 999, 1.7317323684692383)\n",
      "(episode, score, steps, T (mins)) = (25, -99.29841138011255, 999, 1.7263317346572875)\n",
      "(episode, score, steps, T (mins)) = (26, -99.05686078153389, 999, 1.8218207001686095)\n",
      "(episode, score, steps, T (mins)) = (27, -99.37044999635054, 999, 1.7156451344490051)\n",
      "(episode, score, steps, T (mins)) = (28, -99.56293196374122, 999, 1.7349246660868327)\n",
      "(episode, score, steps, T (mins)) = (29, -99.54864852167331, 999, 1.715974752108256)\n",
      "(episode, score, steps, T (mins)) = (30, -99.46994664502894, 999, 1.7215161840120952)\n",
      "(episode, score, steps, T (mins)) = (31, -99.68808688641529, 999, 1.72702716588974)\n",
      "(episode, score, steps, T (mins)) = (32, -99.62654056982794, 999, 1.7205045660336813)\n",
      "(episode, score, steps, T (mins)) = (33, -99.43941098816966, 999, 1.7134127855300902)\n",
      "(episode, score, steps, T (mins)) = (34, -99.35008901797015, 999, 1.7165589332580566)\n",
      "(episode, score, steps, T (mins)) = (35, -99.33649255031322, 999, 1.7312665502230327)\n",
      "(episode, score, steps, T (mins)) = (36, -99.71407861756738, 999, 1.7295211672782898)\n",
      "(episode, score, steps, T (mins)) = (37, -99.53986133434181, 999, 1.7279881834983826)\n",
      "(episode, score, steps, T (mins)) = (38, -99.11713157538837, 999, 1.7209282994270325)\n",
      "(episode, score, steps, T (mins)) = (39, -99.33590803098966, 999, 1.7186145305633544)\n",
      "(episode, score, steps, T (mins)) = (40, -99.6344611219524, 999, 1.7142584840456645)\n",
      "(episode, score, steps, T (mins)) = (41, -99.2568224994731, 999, 2.1436424970626833)\n",
      "(episode, score, steps, T (mins)) = (42, -99.6294398599236, 999, 2.122612249851227)\n",
      "(episode, score, steps, T (mins)) = (43, -99.32622455175579, 999, 1.8085831205050151)\n",
      "(episode, score, steps, T (mins)) = (44, -99.4954114239784, 999, 2.108770716190338)\n",
      "(episode, score, steps, T (mins)) = (45, -99.74702217987573, 999, 2.1507662812868755)\n",
      "(episode, score, steps, T (mins)) = (46, -99.47143192139849, 999, 2.1805229504903156)\n",
      "(episode, score, steps, T (mins)) = (47, -99.56332819590976, 999, 1.8655245820681254)\n",
      "(episode, score, steps, T (mins)) = (48, -99.80257567497296, 999, 1.8587198495864867)\n",
      "(episode, score, steps, T (mins)) = (49, -99.61245472514939, 999, 1.741165300210317)\n",
      "(episode, score, steps, T (mins)) = (50, -99.6803547634653, 999, 1.7044926484425862)\n",
      "(episode, score, steps, T (mins)) = (51, -99.7942027481053, 999, 1.4736270308494568)\n",
      "(episode, score, steps, T (mins)) = (52, -99.7711899360699, 999, 1.3018942475318909)\n",
      "(episode, score, steps, T (mins)) = (53, -99.64140032222993, 999, 1.3136117180188498)\n",
      "(episode, score, steps, T (mins)) = (54, -99.7506265711746, 999, 1.2985008835792542)\n",
      "(episode, score, steps, T (mins)) = (55, -99.59041823143885, 999, 1.2938273509343465)\n",
      "(episode, score, steps, T (mins)) = (56, -99.59439317302304, 999, 1.2903745810190836)\n",
      "(episode, score, steps, T (mins)) = (57, -99.43682416334124, 999, 1.4856637159983317)\n",
      "(episode, score, steps, T (mins)) = (58, -99.48600131116578, 999, 1.324171769618988)\n",
      "(episode, score, steps, T (mins)) = (59, -99.64588412295868, 999, 1.4046745498975117)\n",
      "(episode, score, steps, T (mins)) = (60, -99.6690679290382, 999, 1.319840665658315)\n",
      "(episode, score, steps, T (mins)) = (61, -99.70801373531496, 999, 1.3319883465766906)\n",
      "(episode, score, steps, T (mins)) = (62, -99.85213170323595, 999, 1.5517369866371156)\n",
      "(episode, score, steps, T (mins)) = (63, -99.54005983266913, 999, 1.581263001759847)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from agent import Agent\n",
    "%matplotlib inline\n",
    "\n",
    "#Environment\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "env.seed(1)  # for comparison\n",
    "num_states = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.shape[0]\n",
    "\n",
    "#Agent\n",
    "lr,gamma = 0.001, 0.1\n",
    "agent = Agent(num_states, num_actions, lr, gamma)\n",
    "agent.memory_size = 10**4\n",
    "agent.batchsize = 256\n",
    "learning_start = 25*agent.batchsize\n",
    "agent.tau = 0.01\n",
    "\n",
    "\n",
    "#Train\n",
    "EPISODES = 200\n",
    "MAX_STEPS = 1000\n",
    "scores = []\n",
    "for e in range(1,EPISODES+1):\n",
    "    state = env.reset()\n",
    "    reward_sum = 0\n",
    "    done = False\n",
    "    steps = 0\n",
    "    t1 = time.time()\n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        state = np.reshape(state, [1, num_states])  #reshape for keras\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "        agent.remember(state[0], action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        \n",
    "        if len(agent.memory) > learning_start:\n",
    "            agent.train_models()\n",
    "        \n",
    "        steps += 1\n",
    "        if done or steps > MAX_STEPS:\n",
    "            break\n",
    "    \n",
    "    #Learn & print results\n",
    "    scores.append(reward_sum)\n",
    "    t2 = time.time()\n",
    "    if e % 1 == 0:\n",
    "        print '(episode, score, steps, T (mins)) = ' + str((e,reward_sum, steps, (t2-t1)/60.0))\n",
    "\n",
    "plt.plot(scores)\n",
    "#np.savetxt('stats/scores_inverted_pendulum.txt',scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch a smart agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    state = np.reshape(state, [1, num_states])  #reshape for keras\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    reward_sum += reward\n",
    "    agent.remember(state[0], action, reward, next_state, done)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
