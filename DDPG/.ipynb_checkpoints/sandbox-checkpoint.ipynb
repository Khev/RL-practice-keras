{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kokeeffe/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import gym\n",
    "from critic import Critic\n",
    "from actor import Actor\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Reshape, LSTM, Lambda, BatchNormalization, GaussianNoise, Flatten\n",
    "from keras.optimizers import Adam \n",
    "\n",
    "\n",
    "#Environment\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "env.seed(1)  # for comparison\n",
    "env_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "\n",
    "\n",
    "#Agent\n",
    "lr,gamma = 0.001, 0.99\n",
    "act_range = 10\n",
    "#actor = Actor(env_dim, act_dim, lr)\n",
    "critic = Critic(env_dim, act_dim, lr, gamma)\n",
    "\n",
    "\n",
    "inp = Input(shape = (env_dim,))\n",
    "x = Dense(256, activation='relu')(inp)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "#x = Flatten()(x)   # I assume this is if the input is a convolutional neural net?\n",
    "x = Dense(128, activation='relu')(x)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "out = Dense(act_dim, activation='tanh', kernel_initializer=RandomUniform())(x)\n",
    "out = Lambda(lambda i: i * act_range)(out)\n",
    "model = Model(inp, out)\n",
    "model.compile(loss='mse',optimizer=Adam(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aee3b212e9e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" Define function  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstate_pl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maction_grads_pl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" Define function  \"\"\"\n",
    "#Inputs\n",
    "state_pl = model.input\n",
    "action_grads_pl = K.placeholder(shape=(None,1))  \n",
    "\n",
    "#Find grad_(pars) mu(state)\n",
    "mu_pl = model.output\n",
    "pars = model.trainable_weights\n",
    "grads = tf.gradients(mu_pl, pars, - action_grads_pl)\n",
    "grads_and_pars = zip(grads, model.trainable_weights)  #keras needs this format \n",
    "operation = tf.train.AdamOptimizer(lr).apply_gradients(grads_and_pars)\n",
    "func = K.function(inputs = [state_pl, action_grads_pl], outputs = [operation])\n",
    "\n",
    "#grads_and_pars_pl = [ (tf.placeholder(\"float\",shape=x[0].shape), x[1]) for x in grads_and_pars]\n",
    "#updates = tf.train.AdamOptimizer(lr).apply_gradients(grads_and_pars_pl)\n",
    "#func = K.function(inputs = [state_pl, action_grads_pl, grads_and_pars_pl], outputs = [updates])\n",
    "\n",
    "func2 = K.function([state_pl, action_grads_pl],[operation])\n",
    "\n",
    "\"\"\" Test function  \"\"\"\n",
    "state = np.array([[1,2]])\n",
    "action = np.array([[0.5]])\n",
    "mu = model.predict(state)\n",
    "pars = model.trainable_weights\n",
    "action_grads = critic.find_action_grads([state,action])[0]\n",
    "#func([state,action_grads, grads_and_pars])\n",
    "func2([state, action_grads])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure  tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00171607]]\n",
      "\n",
      " [[0.02899274]]\n"
     ]
    }
   ],
   "source": [
    "#Define model\n",
    "inp = Input(shape = (env_dim,))\n",
    "x = Dense(3, activation='relu')(inp)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "#x = Flatten()(x)   # I assume this is if the input is a convolutional neural net?\n",
    "x = Dense(3, activation='relu')(x)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "out = Dense(act_dim, activation='tanh', kernel_initializer=RandomUniform())(x)\n",
    "out = Lambda(lambda i: i * act_range)(out)\n",
    "model = Model(inp, out)\n",
    "model.compile(loss='mse',optimizer=Adam(lr))\n",
    "\n",
    "\n",
    "#Define the graph\n",
    "mu_pl = model.output\n",
    "action_pl = K.placeholder(shape=(None,act_dim),name='action_pl')\n",
    "pars = model.trainable_weights\n",
    "grads = tf.gradients(mu_pl, pars, -action_pl)\n",
    "grads_and_pars = zip(grads,pars)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "operation = optimizer.apply_gradients(grads_and_pars)\n",
    "\n",
    "#Do the operation\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "state = np.array([[1.2,1.4]])\n",
    "action = np.array([[3.4]])\n",
    "print model.predict(state)\n",
    "action_grads = critic.find_action_grads([state,action])[0]\n",
    "\n",
    "sess.run(operation, feed_dict={inp:state, action_pl:action_grads})\n",
    "print '\\n ' + str(model.predict(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now to figure out how to get keras to do it\n",
    "\n",
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'action_grads_pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9f3b00776bec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_pars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'opt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mapply_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_grads_pl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'action_grads_pl' is not defined"
     ]
    }
   ],
   "source": [
    "#Define model\n",
    "inp = Input(shape = (env_dim,))\n",
    "x = Dense(3, activation='relu')(inp)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "#x = Flatten()(x)   # I assume this is if the input is a convolutional neural net?\n",
    "x = Dense(3, activation='relu')(x)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "out = Dense(act_dim, activation='tanh', kernel_initializer=RandomUniform())(x)\n",
    "out = Lambda(lambda i: i * act_range)(out)\n",
    "model = Model(inp, out)\n",
    "model.compile(loss='mse',optimizer=Adam(lr))\n",
    "\n",
    "\n",
    "#Define the graph\n",
    "state_pl = model.input\n",
    "mu_pl = model.output\n",
    "action_pl = K.placeholder(shape=(None,act_dim),name='action_pl')\n",
    "pars = model.trainable_weights\n",
    "grads = tf.gradients(mu_pl, pars, -action_pl)\n",
    "grads_and_pars = zip(grads,pars)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "operation = optimizer.apply_gradients(grads_and_pars, name='opt')\n",
    "apply_grad = K.function([state_pl, action_grads_pl],[operation])\n",
    "\n",
    "\n",
    "state = np.array([[1.2,1.4]])\n",
    "action = np.array([[3.4]])\n",
    "print model.predict(state)\n",
    "action_grads = critic.find_action_grads([state,action])[0]\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "apply_grad([state,action_grads])\n",
    "\n",
    "#sess.run(operation, feed_dict={inp:state, action_pl:action_grads})\n",
    "#print '\\n ' + str(model.predict(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras for A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_updates() got an unexpected keyword argument 'grads'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f719fcae7df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mdo_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#this is an operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0mapply_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_grad_pl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_updates() got an unexpected keyword argument 'grads'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import gym\n",
    "from critic import Critic\n",
    "from actor import Actor\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Reshape, LSTM, Lambda, BatchNormalization, GaussianNoise, Flatten\n",
    "from keras.optimizers import Adam \n",
    "\n",
    "\n",
    "#Environment\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "env.seed(1)  # for comparison\n",
    "env_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "\n",
    "\n",
    "#Agent\n",
    "lr,gamma = 0.001, 0.99\n",
    "act_range = 10\n",
    "#actor = Actor(env_dim, act_dim, lr)\n",
    "critic = Critic(env_dim, act_dim, lr, gamma)\n",
    "\n",
    "\n",
    "inp = Input(shape = (env_dim,))\n",
    "x = Dense(256, activation='relu')(inp)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "#x = Flatten()(x)   # I assume this is if the input is a convolutional neural net?\n",
    "x = Dense(128, activation='relu')(x)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "out = Dense(act_dim, activation='tanh', kernel_initializer=RandomUniform())(x)\n",
    "out = Lambda(lambda i: i * act_range)(out)\n",
    "model = Model(inp, out)\n",
    "model.compile(loss='mse',optimizer=Adam(lr))\n",
    "\n",
    "\n",
    "\n",
    "#Define model\n",
    "inp = Input(shape = (env_dim,))\n",
    "x = Dense(3, activation='relu')(inp)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "#x = Flatten()(x)   # I assume this is if the input is a convolutional neural net?\n",
    "x = Dense(3, activation='relu')(x)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "out = Dense(act_dim, activation='tanh', kernel_initializer=RandomUniform())(x)\n",
    "out = Lambda(lambda i: i * act_range)(out)\n",
    "model = Model(inp, out)\n",
    "model.compile(loss='mse',optimizer=Adam(lr))\n",
    "\n",
    "\n",
    "#Define the graph\n",
    "state_pl = model.input\n",
    "mu_pl = model.output\n",
    "action_grad_pl = K.placeholder(shape=(None,act_dim),name='action_pl')\n",
    "pars = model.trainable_weights\n",
    "grads = tf.gradients(mu_pl, pars, -action_grad_pl)\n",
    "\n",
    "#Do updates\n",
    "loss = grads\n",
    "opt = Adam(lr)\n",
    "do_updates = opt.get_updates(loss=loss,params=pars,grads=grads)  #this is an operation\n",
    "apply_grad = K.function([state_pl, action_grad_pl], [], updates = do_updates)\n",
    "\n",
    "#Trial session\n",
    "state = np.array([[1.2,1.4]])\n",
    "action = np.array([[3.4]])\n",
    "print model.predict(state)\n",
    "action_grads = critic.find_action_grads([state,action])[0]\n",
    "apply_grad([state,action_grads])\n",
    "print model.predict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change keras source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients_2/dense_13/MatMul_grad/MatMul_1:0' shape=(2, 3) dtype=float32>, <tf.Tensor 'gradients_2/dense_13/BiasAdd_grad/BiasAddGrad:0' shape=(3,) dtype=float32>, <tf.Tensor 'gradients_2/dense_14/MatMul_grad/MatMul_1:0' shape=(3, 3) dtype=float32>, <tf.Tensor 'gradients_2/dense_14/BiasAdd_grad/BiasAddGrad:0' shape=(3,) dtype=float32>, <tf.Tensor 'gradients_2/dense_15/MatMul_grad/MatMul_1:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'gradients_2/dense_15/BiasAdd_grad/BiasAddGrad:0' shape=(1,) dtype=float32>]\n",
      "Check 3\n",
      "[<tf.Tensor 'AssignAdd_1:0' shape=() dtype=int64_ref>, <tf.Tensor 'Assign_24:0' shape=(2, 3) dtype=float32_ref>, <tf.Tensor 'Assign_25:0' shape=(2, 3) dtype=float32_ref>, <tf.Tensor 'Assign_26:0' shape=(2, 3) dtype=float32_ref>, <tf.Tensor 'Assign_27:0' shape=(3,) dtype=float32_ref>, <tf.Tensor 'Assign_28:0' shape=(3,) dtype=float32_ref>, <tf.Tensor 'Assign_29:0' shape=(3,) dtype=float32_ref>, <tf.Tensor 'Assign_30:0' shape=(3, 3) dtype=float32_ref>, <tf.Tensor 'Assign_31:0' shape=(3, 3) dtype=float32_ref>, <tf.Tensor 'Assign_32:0' shape=(3, 3) dtype=float32_ref>, <tf.Tensor 'Assign_33:0' shape=(3,) dtype=float32_ref>, <tf.Tensor 'Assign_34:0' shape=(3,) dtype=float32_ref>, <tf.Tensor 'Assign_35:0' shape=(3,) dtype=float32_ref>, <tf.Tensor 'Assign_36:0' shape=(3, 1) dtype=float32_ref>, <tf.Tensor 'Assign_37:0' shape=(3, 1) dtype=float32_ref>, <tf.Tensor 'Assign_38:0' shape=(3, 1) dtype=float32_ref>, <tf.Tensor 'Assign_39:0' shape=(1,) dtype=float32_ref>, <tf.Tensor 'Assign_40:0' shape=(1,) dtype=float32_ref>, <tf.Tensor 'Assign_41:0' shape=(1,) dtype=float32_ref>]\n",
      "[[0.25662538]]\n",
      "[[0.23807162]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "#Define model\n",
    "inp = Input(shape = (env_dim,))\n",
    "x = Dense(3, activation='relu')(inp)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "#x = Flatten()(x)   # I assume this is if the input is a convolutional neural net?\n",
    "x = Dense(3, activation='relu')(x)\n",
    "#x = GaussianNoise(1.0)(x)\n",
    "out = Dense(act_dim, activation='tanh', kernel_initializer=RandomUniform())(x)\n",
    "out = Lambda(lambda i: i * act_range)(out)\n",
    "model = Model(inp, out)\n",
    "model.compile(loss='mse',optimizer=Adam(lr))\n",
    "\n",
    "#Place holders (think of these as function inputs)\n",
    "state_placeholder = model.input\n",
    "action_placeholder =  model.output\n",
    "grad_actions_pl = K.placeholder(shape=(None,act_dim))\n",
    "\n",
    "#Find log-probs\n",
    "log_action = K.log(action_placeholder) \n",
    "\n",
    "#I want to the gradient to by on the log(pi) only, so 'protect' the advantage\n",
    "# This is the way keras works -- I think!\n",
    "#eligibility = log_action*K.stop_gradient(grad_actions_pl)\n",
    "eligibility = log_action*K.stop_gradient(grad_actions_pl)\n",
    "\n",
    "\n",
    "loss = K.mean(eligibility)\n",
    "\n",
    "#Define optimizer\n",
    "adam = Adam()\n",
    "pars = model.trainable_weights\n",
    "updates = adam.get_updates(params=pars,loss=loss)\n",
    "\n",
    "#grads_in = tf.gradients(loss,pars)\n",
    "#updates, grads_out = adam.get_updates(params=pars,loss=loss, grads = grads_in)\n",
    "\n",
    "#Then return\n",
    "func = K.function([state_placeholder, grad_actions_pl],[],updates=\n",
    "                 updates)\n",
    "\n",
    "\n",
    "\n",
    "state = np.array([[1.2,1.4]])\n",
    "action = np.array([[3.4]])\n",
    "print model.predict(state)\n",
    "action_grads = critic.find_action_grads([state,action])[0]\n",
    "func([state,action_grads])\n",
    "print model.predict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'gradients_26/dense_49/MatMul_grad/MatMul_1:0' shape=(2, 3) dtype=float32>,\n",
       " <tf.Tensor 'gradients_26/dense_49/BiasAdd_grad/BiasAddGrad:0' shape=(3,) dtype=float32>,\n",
       " <tf.Tensor 'gradients_26/dense_50/MatMul_grad/MatMul_1:0' shape=(3, 3) dtype=float32>,\n",
       " <tf.Tensor 'gradients_26/dense_50/BiasAdd_grad/BiasAddGrad:0' shape=(3,) dtype=float32>,\n",
       " <tf.Tensor 'gradients_26/dense_51/MatMul_grad/MatMul_1:0' shape=(3, 1) dtype=float32>,\n",
       " <tf.Tensor 'gradients_26/dense_51/BiasAdd_grad/BiasAddGrad:0' shape=(1,) dtype=float32>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! It works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [0.1,0.5,0.99]\n",
    "lrs = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "taus = [0.0001, 0.001, 0.01, 0.1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.0001),\n",
       " (0.1, 0.001),\n",
       " (0.1, 0.01),\n",
       " (0.1, 0.1),\n",
       " (0.1, 1),\n",
       " (0.5, 0.0001),\n",
       " (0.5, 0.001),\n",
       " (0.5, 0.01),\n",
       " (0.5, 0.1),\n",
       " (0.5, 1),\n",
       " (0.99, 0.0001),\n",
       " (0.99, 0.001),\n",
       " (0.99, 0.01),\n",
       " (0.99, 0.1),\n",
       " (0.99, 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pars = [(g,lr) for g in gammas for lr in lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['1','2','3']\n",
    "np.savetxt('temp.txt',l,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
