{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Here I'm practicing with deep-Q networks on atari games. After I get this working, I'll try switch to the taxi scenario.\n",
    "\n",
    "http://adventuresinmachinelearning.com/reinforcement-learning-tutorial-python-keras/\n",
    "\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import keras as ks\n",
    "import tensorflow as tf\n",
    "from keras.layers import InputLayer, Dense, Input\n",
    "from keras.models import Model\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self,state):\n",
    "        self.state = state\n",
    "        self.epsilon = 0.5\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon_min = 0.01\n",
    "        self.memory = []\n",
    "        self.memory_size = 20\n",
    "        self.batch_size = 5    #how many memories to learn from in experience replay\n",
    "        self.num_states = 5\n",
    "\n",
    "        #Neural net, for predicting Qs\n",
    "        inputs = Input(shape=(5,))\n",
    "        x = Dense(10,activation='relu')(inputs)\n",
    "        predictions = Dense(2,activation='relu')(x)\n",
    "        self.model = Model(inputs=inputs,outputs=predictions)\n",
    "        self.model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def vectorize_state(self,state,num_states):\n",
    "        \"\"\" Given a state = 0,1,2,3\n",
    "            return a 1 hot vector\n",
    "        \"\"\"\n",
    "        return np.identity(num_states)[state:state+1]\n",
    "        \n",
    "        \n",
    "    def get_epsilon_iteration(self,episode_number):\n",
    "        return max(self.epsilon_min, self.epsilon / (1.0 + episode_number))\n",
    "        \n",
    "        \n",
    "    def act(self,state,episode_number = 0):\n",
    "        # epsilon greedy\n",
    "        epsilon_effective = self.get_epsilon_iteration(episode_number)\n",
    "        \n",
    "        if np.random.random() < epsilon_effective:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = self.choose_best_action(self.model,state)\n",
    "        return action\n",
    "                   \n",
    "                   \n",
    "    def choose_best_action(self,model,state):\n",
    "        state_vector = np.identity(self.num_states)[state:state+1]\n",
    "        Qs = model.predict(state_vector)\n",
    "        action = np.argmax(Qs)\n",
    "        return action\n",
    "                   \n",
    "                   \n",
    "    def remember(self,event):\n",
    "        \n",
    "        if len(self.memory) <= self.memory_size:\n",
    "            self.memory.append(event)\n",
    "        else:\n",
    "            self.memory.pop(0)\n",
    "            self.memory.append(event)\n",
    "        \n",
    "        \n",
    "    def learn(self):\n",
    "        num_samples = min(len(self.memory), self.batch_size)\n",
    "        if num_samples == 1 or num_samples == 0:\n",
    "            pass\n",
    "        else:\n",
    "            indices = range(len(agent.memory))\n",
    "            index_set = np.random.choice(indices,num_samples,replace=False)\n",
    "            samples = [agent.memory[i] for i in indices if i in index_set]\n",
    "\n",
    "            states = []\n",
    "            Q_targets = []\n",
    "            for event in samples:\n",
    "                [state, action, reward, next_state] = event\n",
    "\n",
    "                #Find Q_target\n",
    "                next_state_vector = agent.vectorize_state(next_state,num_states) \n",
    "                Q_target = reward +  agent.gamma*max(agent.model.predict(next_state_vector))\n",
    "                Q_targets.append(Q_target)\n",
    "\n",
    "                #Find states\n",
    "                state_vector = [1 if i == state else 0 for i in range(num_states)]\n",
    "                states.append(state_vector)\n",
    "\n",
    "            states = np.array(states)\n",
    "            Q_targets = np.array(Q_targets)\n",
    "            agent.model.fit(states,Q_targets,verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 2000\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Episode 101 of 2000\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "Episode 201 of 2000\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "Episode 301 of 2000\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "model = ks.Sequential()\n",
    "model.add(InputLayer(batch_input_shape=(1, 5)))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "\n",
    "y = 0.95\n",
    "eps = 0.5\n",
    "decay_factor = 0.999\n",
    "r_avg_list = []\n",
    "for i in range(1000):\n",
    "    s = env.reset()\n",
    "    eps *= decay_factor\n",
    "    if i % 100 == 0:\n",
    "        print(\"Episode {} of {}\".format(i + 1, num_episodes))\n",
    "    print i\n",
    "    done = False\n",
    "    r_sum = 0\n",
    "    while not done:\n",
    "        if np.random.random() < eps:\n",
    "            a = np.random.randint(0, 2)\n",
    "        else:\n",
    "            a = np.argmax(model.predict(np.identity(5)[s:s + 1]))\n",
    "        new_s, r, done, _ = env.step(a)\n",
    "        target = r + y * np.max(model.predict(np.identity(5)[new_s:new_s + 1]))\n",
    "        target_vec = model.predict(np.identity(5)[s:s + 1])[0]\n",
    "        target_vec[a] = target\n",
    "        model.fit(np.identity(5)[s:s + 1], target_vec.reshape(-1, 2), epochs=1, verbose=0)\n",
    "        s = new_s\n",
    "        r_sum += r\n",
    "    r_avg_list.append(r_sum / 1000.0)\n",
    "plt.plot(r_avg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remake myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6813c9f3d0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA/crQVzHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('NChain-v0')\n",
    "num_episodes = 2000\n",
    "gamma = 0.99\n",
    "\n",
    "num_states = env.observation_space.n\n",
    "start_state = np.random.choice(range(num_states))\n",
    "agent = Agent(start_state)\n",
    "rList = []\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    total_reward = 0\n",
    "    finished = False\n",
    "    state = start_state\n",
    "    env.reset()\n",
    "    \n",
    "    while not finished:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, finished, _ = env.step(action)\n",
    "        agent.remember([state, action, reward, next_state])\n",
    "        agent.learn()\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    \n",
    "    rList.append(total_reward / (1.0*num_episodes))\n",
    "plt.plot(rList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05733676 0.01079782]]\n",
      "[[0. 0.]]\n",
      "[[0. 0.]]\n",
      "[[0. 0.]]\n",
      "[[0.06088962 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "states = []\n",
    "for i in range(5):\n",
    "    state = np.array([[1 if j==i else 0 for j in range(5)]])\n",
    "    Qs = agent.model.predict(state)\n",
    "    print Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
