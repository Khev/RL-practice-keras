{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "To do:\n",
    "\n",
    "1) Different learning rates for actor and critic\n",
    "2) Fix hack with R0 and D0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "(episode, score) = (50, 8.0)\n",
      "(episode, score) = (100, 12.0)\n",
      "(episode, score) = (150, 12.0)\n",
      "(episode, score) = (200, 50.0)\n",
      "(episode, score) = (250, 36.0)\n",
      "(episode, score) = (300, 38.0)\n",
      "(episode, score) = (350, 44.0)\n",
      "(episode, score) = (400, 11.0)\n",
      "(episode, score) = (450, 10.0)\n",
      "(episode, score) = (500, 10.0)\n",
      "(episode, score) = (550, 9.0)\n",
      "(episode, score) = (600, 9.0)\n",
      "(episode, score) = (650, 9.0)\n",
      "(episode, score) = (700, 9.0)\n",
      "(episode, score) = (750, 10.0)\n",
      "(episode, score) = (800, 8.0)\n",
      "(episode, score) = (850, 9.0)\n",
      "(episode, score) = (900, 20.0)\n",
      "(episode, score) = (950, 77.0)\n",
      "(episode, score) = (1000, 10.0)\n",
      "(episode, score) = (1050, 9.0)\n",
      "(episode, score) = (1100, 101.0)\n",
      "(episode, score) = (1150, 9.0)\n",
      "(episode, score) = (1200, 8.0)\n",
      "(episode, score) = (1250, 9.0)\n",
      "(episode, score) = (1300, 9.0)\n",
      "(episode, score) = (1350, 9.0)\n",
      "(episode, score) = (1400, 9.0)\n",
      "(episode, score) = (1450, 10.0)\n",
      "(episode, score) = (1500, 10.0)\n",
      "(episode, score) = (1550, 9.0)\n",
      "(episode, score) = (1600, 9.0)\n",
      "(episode, score) = (1650, 9.0)\n",
      "(episode, score) = (1700, 9.0)\n",
      "(episode, score) = (1750, 10.0)\n",
      "(episode, score) = (1800, 9.0)\n",
      "(episode, score) = (1850, 10.0)\n",
      "(episode, score) = (1900, 9.0)\n",
      "(episode, score) = (1950, 10.0)\n",
      "(episode, score) = (2000, 10.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbc548927d0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXmYFOW1/79nFnbZR2R1AAFDjICO\niHFf45Lrll+MJDdqNJd4ozd6Nfdesq9ejUbNTaImGk00LsE1anBhEcWN6ICAINsAg4DDMDACwz7T\nfX5/dPVMdXVt3V3dVd3z/TzPPF391ltVZ+rt+tapU+d9X1FVEEIIKV3KwjaAEEJIfqHQE0JIiUOh\nJ4SQEodCTwghJQ6FnhBCShwKPSGElDgUekIIKXEo9IQQUuJQ6AkhpMSpCNsAABg4cKBWV1eHbQYh\nhBQVCxcu3KaqVV71IiH01dXVqK2tDdsMQggpKkRkg596DN0QQkiJQ6EnhJASh0JPCCElDoWeEEJK\nHAo9IYSUOJ5CLyLDRWSeiHwkIstF5AajvL+IzBaRNcZnP6NcROS3IlInIktF5Jh8/xOEEEKc8ePR\ntwG4WVXHA5gC4DoRGQ9gOoC5qjoGwFzjOwCcB2CM8TcNwH2BW00IIcQ3nkKvqg2qushYbgGwAsBQ\nABcBeNio9jCAi43liwA8ogkWAOgrIoMDt7yEWdPYgs/95FU8vXAT1m/bgyfe+zhsk4qSf67bjrqt\nLVlv+/TCTSllM97/GA/MX4e2WDylfO/BNjy7aBOS03I27zmIe+bVoX7bHgBAayyOJ2s3Ih7ntJ0k\nHDLqMCUi1QAmAfgngEGq2mCs2gJgkLE8FMBG02abjLIGUxlEZBoSHj9GjBiRodmlzdl3zwcAfPep\nJZgwvC+WbNyBcz97GPr17BKyZcXFV+5fAACov+2CrLe9cMIQdKkow54DbfifZz4EAJwwegCOGtqn\nve7PXvgIM2o3Yli/Hpg8sj9mLd+CO15dhfpte3DHlyfgvtfX4q7Zq1FZLrhk0rAA/jNCMsP3y1gR\n6QXgGQA3quou8zpNuDIZuSuqer+q1qhqTVWVZw/eTsuyzTsBADFO4h4Kavys20zeeJvFM9+yaz8A\nYM/BtpT1e1tjAIDtuw8AAHbubc2vsYQ44EvoRaQSCZF/TFWfNYobkyEZ43OrUb4ZwHDT5sOMMpID\n1PmQMZ1/dWoMazHbjEQEP1k3AuBBACtU9S7TqhcAXGksXwngeVP5FUb2zRQAO00hHkKKEjWptlW/\nRax13b8TUmj8xOhPBPB1AB+KyGKj7PsAbgPwpIhcA2ADgMuMdS8BOB9AHYC9AL4RqMWdFKVchIqq\n/XJKHUsbWb+L9Y5ASIHwFHpVfQuA0y/0TJv6CuC6HO0iJBIkRd0q4X42YriNRAX2jC0WKBqhYo7L\nOwm4WPwhCj2JChR6QnygDsupddR2PQWfhA2FvkigVoSLW4zeGtfsCPew1Ug0oNAT4oOUrBsHF91a\nnPzOd7AkbCj0RQIf/0NGbRftq1oai21HwoZCT4gP4i6hGye88u0JKRQU+iKB8d5wSe0w5Z4fn1xL\nT55EBQo9IT5QP2k3dnUJiQAU+ojjOK4KKSi+0ivTViTTLdmGJFwo9Fly5p2v45y73yjY8aj34dCe\nKumjw1T7eod6DNGTsMhoPHrSwdqmPWGbQApISh69Tw+d92YSFejRR4zq6TNtyyka0cG7wxRbi0QL\nCj0hPkj16B3q+NiWkDCg0Eecjngv1SKf7NzbilHfm4k31zTZrnfrGeuUH5/WZkykJyFBoScEwPJP\ndiKuwD3z6lLK2wcqc/HonYY+SE/C4c2ahAOFPuJ0ZH2Ea0epkzy91qGGrevTv7jsk2PdkIjgZyrB\nh0Rkq4gsM5XNEJHFxl99cuYpEakWkX2mdX/Ip/GEBIWXKKekV6b1jLXUtQxXzJs0CRs/6ZV/AfB7\nAI8kC1T1K8llEbkTwE5T/bWqOjEoAwkpBElxdhR687LTVIJeM0vRtSch4WcqwfkiUm23zpg4/DIA\nZwRrVueEL1zDxzF04zqomdM2bE8SDXKN0Z8MoFFV15jKRorIByLyhoicnOP+OxVuukDNyC/OXnr7\nEtKXHLYJwiBCAiTXnrFTATxh+t4AYISqbheRYwH8XUQ+q6q7rBuKyDQA0wBgxIgROZpRGlAgwqP9\nZaxDdOWTHftz3jchYZG1Ry8iFQAuBTAjWaaqB1R1u7G8EMBaAGPttlfV+1W1RlVrqqqqsjWj08CB\nsfKLV5jle89+6LuuU6YUI/QkLHIJ3ZwFYKWqbkoWiEiViJQby6MAjAGwLjcTOw+M6YaPdWz5JKlZ\nN/a0Z9nwpkwihp/0yicAvAtgnIhsEpFrjFWXIzVsAwCnAFhqpFs+DeBaVW0O0uBSxk0eeA/ILx15\n9PaYbwB+O7xS8ElU8JN1M9Wh/CqbsmcAPJO7WZ0Tinl4JD329Jx42JRnFrphu5KwYc/YCOHmAVIr\n8kt7hymH9Wah9z1nLBuNRAQKfYQ40BYP24ROj1OM3pxfn+kolewnRcKGQh8h7nmtzrsSyQte3reb\nR++k44zRk6hAoY8QO/e1Oq5jRk5+8XwZm1LXK0afOhQCm46EDYU+QlAQwsPxZWx7uXPWTfq+7MsZ\nwiFhQaEvEngPKBROMfoO/LYF24xEBQp9hGBMNzw8z3xKjN69y5TN8DiEhAqFPkJwULPw8BqP/viR\nAxy39e4wxcYj4UKhjxCUgzAxYvEOa8cN6tVR02OkS8cYPUe7ISFBoS8aeBvIJ04evZ1P7pl1YzPP\nLCFhQqGPEBSG8DgYS3RWc/K6464TjyRwukkQEjYU+gjhOgQCVSOv/OjviSmRm/cetF2fMnplhqEb\nth0JGwo9IQB27W8DALQYn25Yddt5+kEqPIkGFPoo4ZZ1UzgrOjVO4hxP8ejt61jj+V6zVhFSKCj0\nhLhgF47xvOkalZNx/V0+nhIIyScU+gjBiUfCJ+7hrad/cUEVew60YebSBgD07El4UOgjBGO64RN3\naIKU0I1F6d1SMncfoDdPwsfPVIIPichWEVlmKvupiGwWkcXG3/mmdd8TkToRWSUiX8iX4Z0NDo9Q\nGBzj7z7SK+22cXpCIKSQ+PHo/wLgXJvyu1V1ovH3EgCIyHgk5pL9rLHNvcnJwgkpBvzIstfEI8lP\nijyJCn7mjJ0vItU+93cRgL+p6gEA60WkDsBkJCYXJx4wRh8ME342C58b2ie7ja3nOSnappiO5zDF\npp6x5roM0ZOwyCVGf72ILDVCO/2MsqEANprqbDLKiA8o5sGwc18r3qrbltW27uNSJpf9NZSCXj2J\nBtkK/X0ARgOYCKABwJ2Z7kBEpolIrYjUNjU1ZWkGIcGSTYw+fbIS+31R8klYZCX0qtqoqjFVjQN4\nAInwDABsBjDcVHWYUWa3j/tVtUZVa6qqqrIxo+Rg6CZ8nD16zagOkB66YRuSsMhK6EVksOnrJQCS\nGTkvALhcRLqKyEgAYwC8l5uJhBQOp1BLStqlpY51CISO9EpNqRqj0pOQ8HwZKyJPADgNwEAR2QTg\nJwBOE5GJSPym6wF8CwBUdbmIPAngIwBtAK5T1Vh+TC893PLomV5ZGLpXpiaJtZ93U9v86Pnl+PwR\nAzG6qhfscBrcLGaMkElIofH06FV1qqoOVtVKVR2mqg+q6tdV9XOqerSqXqiqDab6t6jqaFUdp6ov\n59f80oJSHh6XH5eIOF5WM9z2hmstefL9jWl1rMRVU27QTp2xCMk3nh49KSCcSjA0ulQkfJ6nF27C\nkk0709Zncv7b0yuRKu7MwCFhQaEnxMTKLS1YuaWl/ftNTy5JePk+nrfSdNwauqFLT0KCY91ECMbh\nw8PJ2X5t5VZc++jC9MlEzF+sPaFMPWPNYSDqPAkLCn2E4JN98eBnADqGbkhUoNAXCRub94ZtQknj\nPeF3JvsyPi0btcUo9CQcKPRFwg0zFodtQqfGjzPeIfDJl7EK8y0iFmd6JQkHvoyNAPG44s7Zq7Bl\n137nSnQG80qmURU/g5XF46mhG3aYImFBoY8Aiz7+FPfMW+tah7MT5RcvCfb7orw1FscDb65v//7P\n9c0d+6DOk5Bg6CYC7G/1fqSn0OcXTxF2y7ox8fziT0z7VPzo78s6vmdnGiE5Q6GPAK0+usZbx1Mh\nwfLq8i0Z1Xe6MTSawm/WKsy6IWFBoY8AvoSeOp9XmvccdF3va+Yp1ZROUWnCTp0nIUGhjwCtPtLu\nqPPRRUx34ZjLTFTUeRIWFPoI4M+jp9SHiaqizNQEGz+179eQIvSWdXF2jSUhQaGPAAzdRB9VoMzU\nCLM/arSt15bi0XOGKRINKPRFAnU+fPzcbM1x+bTQDZWehASFvkhg6CZcFP7awDV0Q6UnIUGhLxKo\n8+GSCN3YrzMXx1xCN4SEhafQi8hDIrJVRJaZyu4QkZUislREnhORvkZ5tYjsE5HFxt8f8ml8VFj0\n8ad5H2ucOh8+Xn0ZVFO9dutPgsJPwsKPR/8XAOdaymYDOEpVjwawGsD3TOvWqupE4+/aYMyMLrX1\nzbj03ndw77y6vB6HoZtwUaijR28mNUavlnVBW0WIP/zMGTsfQLOlbJaqthlfFwAYlgfbioKGnYme\nkCsbWzxq5gZlPlysWTdu9dqXreuYd0NCIogY/dUAzJOAjxSRD0TkDRE52WkjEZkmIrUiUtvU1BSA\nGeFQqEuXHn0EcIrRO5Qz64ZEhZyEXkR+AKANwGNGUQOAEao6CcBNAB4Xkd5226rq/apao6o1VVVV\nuZjRKaDOh4+fJjBrOUM3JCpkLfQichWALwL4mhq/aFU9oKrbjeWFANYCGBuAnZ0e6nx+iMfVc5wb\nICHaXk9VitQ5YtN1nUpPwiGr8ehF5FwA/w3gVFXdayqvAtCsqjERGQVgDIB1gVgacfItxPTo88Pd\nc1bjd6/5e5Hupw1SYvQM3ZCI4Cn0IvIEgNMADBSRTQB+gkSWTVcAsw0vZ4GRYXMKgJ+LSCuAOIBr\nVbXZdsckIzhMcX6Ytdx+KAMrfjXaLObWDlLsMEXCwlPoVXWqTfGDDnWfAfBMrkaRdA4f0CNsE0oS\nv09Kqs5PbeZyc2ZNWtYNdZ6EBHvGFgkXHD04bBM6PZ4xerWIuUXY+TKWhAWFvkhg4CZc3HLgzTeA\nVJ1P3eaZRZuwYN32oE0jxBMKfY4Uqls7ncFwcQvdqMOIlXYTysxbtTVgywjxhkIfEOzQVPr4yrrx\nuCV3LeclRwoPf3UB8eKST9CyvzVsM0iG+L1Bu8l3yj48Hr0qKfQkBPirC5CPm+2nlyPFTyIk4+Nl\nrMd+Kit4yZHCw19dkcDUvPAxO+7D+nXvKDfV8Xpn42cETEKChkJPOjX+dTdVwPv37GJbw+t+zBRL\nEgYU+gCh1126uGXdWOvlsp6QfEChLxI4O1F+yCRZyquuwI9Hz3YkhYdCTzo1mQyB4FnH134o9KTw\nUOgDhNdw6aJQ54HlTMVeHjt/IyQMKPQBks+p4qgPwbO/NYZlm3f5ru/l/auqp8fOl7EkDCj0pNPy\nyrItvuta9dtJ82MeSs55Y0kYUOgDhI/lxUUmL0YV/rJuvDx2evQkDCj0EYDXfjh4ed9WnIZLMMfu\n48Y+bzxrjG1dvowlYUChz5FCXbfUh+DJ5Jz6rRtXxdHD+uDGs+ynSmY7kjDwJfQi8pCIbBWRZaay\n/iIyW0TWGJ/9jHIRkd+KSJ2ILBWRY/JlfNTgNVxcxDIK3XjXVQAxdR8ojXn0JAz8evR/AXCupWw6\ngLmqOgbAXOM7AJyHxKTgYwBMA3Bf7mZGl5SBC3kRFxWPvLsho/r+JgdXlLvU4y+EhIEvoVfV+QCs\nk3xfBOBhY/lhABebyh/RBAsA9BWRkp0HLwht99W1PvfDEBNrm3ZjRYP/1Eq/DRBXRRk9ehIxconR\nD1LVBmN5C4BBxvJQABtN9TYZZSmIyDQRqRWR2qamphzMiA7ZXsK89AtPayyeUX2Fs0dvLo/F3YWe\nOk/CIJCXsZqIWWT0E1bV+1W1RlVrqqqqgjAjdHgRlzYpPWPtxFwT6ZNlLlcVw3skDHIR+sZkSMb4\nTE6GuRnAcFO9YUYZyQEKRLiknX/Td7Pkxz08+pVbWgK2jBBvchH6FwBcaSxfCeB5U/kVRvbNFAA7\nTSEeQooSt9CN+RYQU0W5y+wib67ZFqhdhPjBb3rlEwDeBTBORDaJyDUAbgNwtoisAXCW8R0AXgKw\nDkAdgAcAfDtwqyNEatodve5SJkW+HVQ/Fu8Q+vGDewMAjhraO8+WEeJOhZ9KqjrVYdWZNnUVwHW5\nGNWZWNGwCzv3clLxqJMWOXMI3bTFFBVGkP7WSz+Hi+552zWUQ0gh8CX0xB/ZhNHP+783bctF+HI3\nSiRCNx6Tg0MRiysqDI8+2XyUeRI2HAIhQILUZYpDfsnmJuoUujHrf1s8jnKjxxRfoJOoQKGPKF7e\nIyksVtF2et/aZufRm9pycnX/fJhHiCsU+ohi1RE6hxHA1ChOcXdzjD7ZZuaqbhk5hOQLCn2OmAU4\nSDGmQx8trE3rpNfmGL1dMI8Tj5AwoNAHSJAxWcf5SUkgZHwj1dSnLLvQmmoidJOM0Vf16gYAOGHU\ngCytJCQYKPQ5kjfPmzofOczibvbozTflWDyOcqPeiAE98MZ/nYabzxnXvp4hOBIGTK/MkZTQTYD7\ntYYG+MgfLtbz7/TEpUhtu8MH9MyjVYT4gx59RClnkD6vZOpZqyV04zRwmdd+ebsmYUChz5F8vYxl\nb8roIR5ZN4rEexqmxpKoQaEPkCDDK1atYGw3v8y56VTX9dbzLw4dpjxhO5IQoNDnSL6cN+ZbF5Zh\n/bq7rldoSlzeqXmo4ySKUOhzJF+eNoU+eniFbgAk0jBtVs377mk4pBtzH0g4UOizYH9rzH5FoB2m\nUtWCnmK4pIVuXOraZeSMHNgTRw3pw+wpEgoU+izYtvuAbXk80Jexwe2L5E7aKMV2ddT9hsx3tCQs\nKPRZ4JRVEaS3xvTK6OHU7ubiRNaN8z74Up2EQdZBQxEZB2CGqWgUgB8D6Avg3wA0GeXfV9WXsraw\niMg8N9t5A6boRYv0KWOdx7Fxajk2KQmLrD16VV2lqhNVdSKAYwHsBfCcsfru5LpSFHmn6zVTZ83t\nxmDtkENPMGwUgo40TKfm8GomNiMJg6BCN2cCWKuqGwLaX6RJeVQ3lWc6qJlbbYZuCseDV9b48rZF\ngCMO7YUJw/o41lGHrBuAA9WR8AhK6C8H8ITp+/UislREHhKRfgEdI/IEGbop49vYgnHmZwZ51kkP\n3TjXdQu7cdYpEgY5C72IdAFwIYCnjKL7AIwGMBFAA4A7HbabJiK1IlLb1NRkVyWymD0z8yWd6ctY\nt9rWPG2m5YVLYs5Y44tI2hBnHfXc3rvkwTBCfBCER38egEWq2ggAqtqoqjFVjQN4AMBku41U9X5V\nrVHVmqqqqgDMCIfU0E1w+6VDHz2SN3jHdzSaPvgZIVEgCKGfClPYRkQGm9ZdAmBZAMeIFI6dIrMY\nEdEJDmpWWLzi59aQi2sIxi29MhOjCAmInPpki0hPAGcD+Jap+HYRmYjEb7resq4kSAnXmC74eMYv\nY11i9NbQDRUiVMyhG9c8+YJYQ0hm5CT0qroHwABL2ddzsqjIUIdlX9u6bMCxbqKHr/x4dX864A2b\nhAF7xmaD5cJuX2SMvmQxt63Avq2TRY7plQzHkZCg0OeI5uDTZ5uiR4LH63SrqZK1bTLJvKJDT8KA\nQp8jleUdpzDjl7Eulz1DN9HDSdCtmVeOIZ58GEWIDyj02WB+jDddvZmOXumedZPZvkh+Mb90dwrd\ntK9n25GIQaHPAqfc+Xx2mCLh45R14/DKxh6+jSUhQKHPkVwmB3cdAiEtvZICkU/83FZT02ptKqgm\nhil22Bvv3SQsKPRZkOrF2y/72o/LOsboo0Vq1o3lZazVw2eePYkYFPocMXvaGY9eyThv0aDQlGwb\npzCd6wxTAdtEiF8o9FngeJEH6NIzRh89xLTg1NZeY90wAkfCgEKfBc6hm9yv4u+ccQSA9NANBSJc\nrB2mXHGccpA3bxIOFPpcyeFl7IFYLL3QEAOG6AuLlwhbJxSxfRfr4zgcbpqEAYU+C5y8+EyF/paZ\nK9LKyszxARIp2ocpFqT2pTDKk+3PDlMkalDos8DppWumo1cu27wzraxMTGJiPmZGeyZBY76hew1p\nzAgNiRoU+hxxitf7oWtFeVqZWD5JNFBFSqPYhWD8ZF3xXQsJAwp9FjiKe4YXcdfK9NOfnCuWXmFh\nyaTDlOPEM+312GGKRIucxqMvdlpjcew9GEOf7pWedeNxxa79rWnj2eQyBELXinShD2r2KhIsFoc+\nNQtHUstcO0yxHUkIdGqP/oa/fYAJP5vlq+5v5q7BxJ/PxjG/mI26rbvby83inumgZt0q00M3SZhH\nHzFMWTci2WbdsE1JOOTs0YtIPYAWADEAbapaIyL9AcwAUI3EdIKXqeqnuR4raF76cIvvuq8sa2hf\nXtu027bO/tYYDrTF0KW8zFfO9KGHdPV9fBIs2XjWHZOD27dtMkbv2mEq88MSkjNBefSnq+pEVa0x\nvk8HMFdVxwCYa3wvGZwGMvvZix9h3A9fwaMLNljqq+2LusF9uufLxE5LtoO/eU884n9ycOcZpjK1\nipBgyFfo5iIADxvLDwO4OE/HKRhOsXi7y/3FpQ0p30d+7yXc/OSStHr/N3eN4/HSRq+kLxgo2Yiu\nV+jGDxyFlIRBEEKvAGaJyEIRmWaUDVLVpNptATAogONEhpRYvNvkoSae/WBz3uwhHfjV0cyHlHZe\nl7xnJPtROIXt6NCTsAhC6E9S1WMAnAfgOhE5xbxSEy5M2mUiItNEpFZEapuamgIww5lz7n4DF/3+\nrcD2d9vLK13Xv1ffjP96Kt2D9yJlfBuqQlbky19WWIZAsLu/01knESVnoVfVzcbnVgDPAZgMoFFE\nBgOA8bnVZrv7VbVGVWuqqqpyNcOV1Y27sWRTei/UTHC6hp3Kn1q4KeNjvHLDye3LVp2niPjDb2jE\nGgrz8/K8YwgE3oVJcZGT0ItITxE5JLkM4BwAywC8AOBKo9qVAJ7P5ThRJlsBfm99c1rZ4L4dL2cp\nJtmRN4/e0tBu6ZV8GUuiRq7plYMAPGeIUgWAx1X1FRF5H8CTInINgA0ALsvxOHlFVT2F1clTzObl\n2r6DMVz2x3fTyis4ZGXByDhGD9PLWIcddAxq5tyOfDIjYZCT0KvqOgATbMq3Azgzl3375eJ73sbZ\n4wfhutOPyHof1iFoM9o2i20279hrW26O0aeFbrI4TmekEEKaPnWgMXqlRyt5DYZGSL4o+p6xizfu\nwB2vrsppH/7GEc9iv6r44u/etCm3r2/26PmYnx35SkO1tpnD3OAAvOaM5S2bFJ5OPdZNErUOTZjR\nts7rHnxrPZZt3pVS9u+PLkSVQ49YEUEsltghJwfPjnx59InQTbJnrDuO49GzSUlIUOjh01t3miPU\nZZNfWiYWUVW8vMx92IU2I0m/sqzoH7YiTXZDIOS2PSFhQTVBbhdtJi9jW2PedWOG0FeUW2ceobKE\niun8i4htCCYeT3aY8rUbQgoGhR7+4qZBXJ9+ZqDi431u+O4Zm2GLpmXduMDx6EnUoNAjNy9rf6vN\nBN8OtPkYx7iyPNEkrbF41jZ1ZnJ52eklxF6hm3y91CckVyj0OfLsIv9j2Bxs8xbvLhVJoffuoEPS\nydvLWMtEI25DIDh2mGJ6JQkJCj38iYNTLD55UV9z0kjPfVz/+CLPOl89fgS+ePRgXHvqaG+jSBp+\ndT7zDlPmTnUO49H7CQEySE9CgEIP9wv0T2+uw5rGFtRvt+/klLz4/Qj9O2u3e9bp3a0Sv//qMejf\ns4tnXZI9yz/Z5V3JQkroxlxumUrQ1w4IKSBMr3RBVfHLmStw56zVjnWS125vH/POZgLT6LPDr8f8\n/ec+TCsTOD8RLNu8C7v6tyXqeU0O7hLspz9PwqBkPPoH5q/L+rHYabNkquM+lxeua4z5Y8sEuHDC\nkKyOb4dVLPjE7498nqaPmzue6sy/tfbYu8dUgrx3k7AoGaG/5aUV+GDjjqy2fXW5fScmP1kySQQS\n6KBk9OizoyBj3ViPST+dRJySEXoAaPPRIcmOm2ym+QP85b0nEQl22AIOU5wf3qnbhmWbc5ubwDt0\n47Ix7wkkBEoqRh+0NsYy8OgBm96sOWD9X+g1+sTmNLXF4nh64SZ8uWY4vvqnfzpuKk55k3aHMadb\nGj5+xzDFLvsnJARKSuiD5oCPvHcz1gm9cyHIfXUm7G6If3mnHr+cuQJzVqRNdJYVAvshEGIec8Ym\n7COk8JRU6CZoafzd3DW+61aUdcToxw7qlfGxDrWMaMkYfXbYOeS19Z8CAOasaAzkGOnj0Sc+24ze\nzE5PdmxSEhb06F1o3HXAs063yjKMGtgLFeVlKDPU+bKa4SgvE/zsxY98HytNPMCsm2ywO02vOLxs\nz5RffelzHcexOVCyN7PbyKPsMEXCIGuPXkSGi8g8EflIRJaLyA1G+U9FZLOILDb+zg/OXC+bCr+/\nWFzbX8J+4bOHAQCmjBoAv+H9k8cMBJAeqmHkpvB4vZNJjkPk1DaOI48asE1JWOQSumkDcLOqjgcw\nBcB1IjLeWHe3qk40/l7K2Uqf7G/tiKm3xeJYuCF9Au5M8BMnb41puyc/ZdQA1N92AY4a2qfdcxs3\n6BDb7SZX90f9bRfg5nPGAUh/rKcoZEc+Peak0AP2Tw5t8cTvzy37iv48CYOshV5VG1R1kbHcAmAF\ngKFBGebThpTv059d2r7861mr8aX73sXCDZ9mfwCfYmvnwCW9ux5dy223ST7dt4+eYlF2vozNjnwK\nabtHD7G9oWzffTClnhW2KAmLQF7Gikg1gEkAkrlr14vIUhF5SET6OWwzTURqRaS2qakpq+Nar7WN\nzfval1c0JMYyuWu2/Xyyfjw/v2JbYROTPebwxL899bgR7WXHHt4PD11VAyDd67MeynpseoL+yGcI\nvEuF/YD0ya+zPkq87N222/vdDiGFJOeXsSLSC8AzAG5U1V0ich+AXyChTb8AcCeAq63bqer9AO4H\ngJqamqwuT6eNGnftR8v+VgArOWc7AAAQl0lEQVTAyoYW2zoz3t9oW97UcgBdysvQp0clRg7s6csO\nu3dvx1X3x4c/PQeHdKvE+UcPRpkkPL1PdiRuRmccOQhAh8Cnxeh9HZlYyWd/A6fQTbnlka55z0HH\nffBdLAmDnIReRCqREPnHVPVZAFDVRtP6BwD8IycLXUiKuZmNzXtx8u3z2r9vd7jokh5/kng8EWs/\n7pY5EAHW33oBRvkUeicO6ZYY6KxX147TfPiAnlj0o7PRr0fqIGhOKXskOiSf3ARIUfpuFanhufGD\ne9tuzw5TJCxyyboRAA8CWKGqd5nKB5uqXQJgWfbmuVNnDChmxizyVvYddB6cLKaKnXsTN46k1+XX\nO1ywLrOXvv17dmm/6JNplOlZN5Ii9vQEfZLX0E0y68ZdsM8xsq/sYA9nEga5xOhPBPB1AGdYUilv\nF5EPRWQpgNMB/GcQhtqR6dgyB9pchD6umPDzWe3f97fGsHt/W9a2ZYrdf0L/L3OCktFzxg9KK+tr\negrL5jhsTxIWWYduVPUt2P92C5ZOafcS1A2zV2xNmd5zIFXUT7ztNcewT5C0TzhtcybLRDIaWI0E\n9+Rj9yK+X4/EZDC5CDabk4RBUQ+BkKlHH1dFLK5oi8XThiA+9pdzUr4XQuTN2IUDmGKZOUGERv50\nRU3ajffVG09JmfXLnLXl+4hsThISRT0EQqajRcbiilNun4cdew/igqMHe29QQGzvWeYYPWO7ead6\nQA/Ub9+L3t0r0zzvcYd1dHwTyT5ERI+ehEFRe/SZTvTRFlds3rEPew7GMppUpBBYx7ZJlJFMyUVI\nTxt3KIDULCk72C6k2Chyoc/MfPNYJvEAhf7WSz/nXckBtxg9IzeZY9eq150+2te23z//M3jsm8dj\n/JDU9MgrTjg8/ThZ/HzsbuaEFIKiFvruXeyHF3DCLPRZTkZlSy4zS7VPVuGl6tF6AIksdj2ej6vu\n71i/p+k31KWiDCceMTCtjjlsAzAfnhQfRR2jr7KM4e5FW548+iD2ZXevoAcYDF0tHZpG9O+Bj5v3\n4o9fPxZHD+uT1T5T3pn4dO95fyBhUdRCnymPvFvfvpwcaTAI/t+xw7Letr1zlo1W9OxagX2tzrn/\nJB2789ine0f++x+/fiyOq+6P2vrmrDs2ic1xRICnrz0h5Vj29vHRjBSeohf6rhVlvqf8e+TdDe3L\nry4PZrYhAKhwGK3QD4f2TjyV2L0A7NO9on2ALObTZ0fN4f1SYu7JOQPcRN5K2pOVg2d+7OHOISKX\nzQjJO0UdoweA0VXe0/YN7ds95+McPzL1Iu7TvRIvXH8iHv/m8Tntd1Dvbrj7KxPw26mT0tatbdrT\nvrzDGJ5h7opGnHHn6zhoc3PbsfcgTrtjHpZs3NFeNn91E75w93zsb43hO098gJ+/+BFO+tVrWLpp\nR8q2B9piqJ4+E2fd9YajrfsOJuqM/cHLKeU/fn4ZqqfPxF2zV/v7p32wc18rTr79Ncdhpve3xnDG\nna9j/uom3Pi3D1A9fSZGf/8lnH13qv2XHTccAPDSd07GI1dPDsw+VeCyP76Lh9+pz2w747NlfyuO\nu2UOvv3YQlz15/eytqNuawuO/9857YPlAcBPnl+Gm59c0v79nnl1+ObDtXj5wwZUT5+Jz986F/td\nnhR37mvF6b9+vf3cX3rv2ylPw2YuufftjM9BNnzjz+/h3tfrUspeX7UVJ7j8L396cx0uufdt3Pi3\nD3DrSysAAFtb9mPyLXOw/JOdjsdatnknTrh1LrbtPoAH5q/D1PsXoOaXc1A9fSaWbNyBKx96D/fM\nS7Xllpkf4b+fTpzzX7+6Ctf+dWH7ur0H21A9fSbG/bDjulm44VOc/uvXsXNf+nhd+UCi8ChZU1Oj\ntbW1WW178T1vY/HGHa51vnFiNf78dr3tumtOGokH31rveZz1t56Pvy7YgC8ePQTzVzdh4vC+qM5x\n0DMvqqfPzOv+w2TCsD7o2bUC76zdntfj/OYrE3HxpMynSfjuU0vw9MJNABJZVVMndww3fdOTi/Hs\nos1p29TfdoHrPr/6wAK8s3Y7xg06BKsa7UdVLRX6dK8smIgVkooyCTw1+2vHj8Atl2SXuSciC1W1\nxqte0Xv0937tGJx4xAD8+IvjHesc1rsbqgf0sF33I5ftktk03z//SIgIrjihGv17dsHFk4bmXeQB\n4OGrJ+PIww4pyZd4SzbtzLvIA8ARh2Y+UTsA/PTCzwIAThlbhdPGVaWs61aZWbZXkuT/W+oiD6Ak\nRR5AXvrfFOI9XNEL/ZC+3fHYN6fg6pNGto8uaOWqE6sx41snpJXfeNYYAMC3T0vkWQ/p0w03nT0W\nYwxxePSa4/HDCz6Daaf4y8MOmlPHVuGVG0/Bo9f4Dw+ZPc/Oziljq/DZIfZDBnvRq2sF6m+7AI9c\nPRmD+6SG/m46e2xW+xzR397ZiBKTXVJRiTtTJw/Parv/zdKbz4SiD92Y+XDTTtRuaMZlNcMx6Rez\n8c2TRmLC8L7tL+BeWPIJVBXLNu/ETWePc8zD39i8F3//YDOuP+OISOVMqyp+M2cNLj1mKEb074Fr\nH12IV5c34qihvXHmkYNww5ljUFYm+MfST9CtohxnGSMwPjB/HQb37Ya1W/fg2MP74WcvLkdrLI5h\n/XrgrbptuHDCEJw1fhAunDAEew+24Yd/X4YeXcpx+XEjcP3ji3DHlyegftse/NfTSzF18gjccvFR\n2LbnAB58az2uOKEajy7YgG+fNhq/nbsGK7e0YGjf7ujdvRLfPm00+vbogpc/bMC/P7YI/zJhCH50\nwWcw4/2NGN6/B26csRhXfb4aIwf2xMotLdi++wAG9OqKiyYOwWG9u+Frf0pMWPa7r07Cayu24uF3\n6tFyoA23f+lo/H3xZiz/ZFcilj9mIN5csw3/edZY3HDWGCz/ZCfeXbsd3zx5VN7aIhZX/N+c1Zg8\ncgCeXrgRV36+GpNG2E6m1s66pt341SsrcbAtjvFDeqN3t0rMX9OEe792LPp0r8S9r9dhY/M+fLlm\nGH7xj49w2thD0bNrObpUlOGPb6zDZiMOP3XyCEwa0RcVZYKbnlyCuTefitZYHH99dwMmDO+L5xdv\nxtt12/G7qZMwZ0Ujnl/8Cb5SMxwzajeiR5dyPPPvn8d1jy9C/bY9+PM3JuPUsVVY3diCWcu34LrT\nE7/5JRt34NlFmzByYE88tXATnpg2BRf+7i3865TD8eiCDWjYuR8njxmIt+q2oaKsDBOH98W1p47G\num27cdHEobhnXh1uOnssulWW4/nFm7FgXTNWN7bgoolDUCaC5j0Hcdfs1fjHf5yEo4YmUlxr65ux\ncksLLj9uOO6YtQoDenbBn9+uR0W5YGPzPsyYNgWvr27Cd88Zh537WnHX7FVYv20PykTQvbIc5x51\nGI6r7o97X1+Lf50yAi8uacAf3lgLAHj8347HvJVbUVFehl37WrFySwsaduzDtaeNxthBh+CKB9/D\nCaMH4I3VTfjHf5yENVtb8J8zlmBgry7o0aUCA3t1waKPd+Bbp4yCArj21NFo3nMQZ931Bo487BDM\n/M7JKC8TfO/ZpXjivY244OjBOPPIQzGgV1ecOrbjifDBt9bjvfXb8T/nHokXlzTg4klDcPiA7KMD\nfkM3JSX0hBDSmeg0MXpCCCHuUOgJIaTEyZvQi8i5IrJKROpEZHq+jkMIIcSdvAi9iJQDuAfAeQDG\nA5gqIs55jIQQQvJGvjz6yQDqVHWdqh4E8DcAF+XpWIQQQlzIl9APBbDR9H2TUUYIIaTAhPYyVkSm\niUitiNQ2NTWFZQYhhJQ8+RL6zQDM3cSGGWXtqOr9qlqjqjVVValdzAkhhARHXjpMiUgFgNUAzkRC\n4N8H8FVVXe5QvwnABrt1PhkIYFsO2+cL2pUZtCszaFdmlKJdh6uqp6ecl/HoVbVNRK4H8CqAcgAP\nOYm8UT8nl15Eav30Dis0tCszaFdm0K7M6Mx25W3iEVV9CcBL+do/IYQQf7BnLCGElDilIvT3h22A\nA7QrM2hXZtCuzOi0dkVi9EpCCCH5o1Q8ekIIIQ4UtdCHOXCaiAwXkXki8pGILBeRG4zyn4rIZhFZ\nbPydb9rme4atq0TkC3m0rV5EPjSOX2uU9ReR2SKyxvjsZ5SLiPzWsGupiByTJ5vGmc7JYhHZJSI3\nhnG+ROQhEdkqIstMZRmfHxG50qi/RkSuzJNdd4jISuPYz4lIX6O8WkT2mc7bH0zbHGu0f51he06z\n5zjYlXG7BX29Otg1w2RTvYgsNsoLeb6ctCG835iqFuUfEmmbawGMAtAFwBIA4wt4/MEAjjGWD0Gi\n38B4AD8F8F2b+uMNG7sCGGnYXp4n2+oBDLSU3Q5gurE8HcCvjOXzAbwMQABMAfDPArXdFgCHh3G+\nAJwC4BgAy7I9PwD6A1hnfPYzlvvlwa5zAFQYy78y2VVtrmfZz3uGrWLYfl4e7Mqo3fJxvdrZZVl/\nJ4Afh3C+nLQhtN9YMXv0oQ6cpqoNqrrIWG4BsALu4/lcBOBvqnpAVdcDqEPifygUFwF42Fh+GMDF\npvJHNMECAH1FZHCebTkTwFpVdeskl7fzparzATTbHC+T8/MFALNVtVlVPwUwG8C5QdulqrNUtc34\nugCJXuaOGLb1VtUFmlCLR0z/S2B2ueDUboFfr252GV75ZQCecNtHns6XkzaE9hsrZqGPzMBpIlIN\nYBKAfxpF1xuPYA8lH89QWHsVwCwRWSgi04yyQaraYCxvATAoBLuSXI7UCzDs8wVkfn7COG9XI+H5\nJRkpIh+IyBsicrJRNtSwpRB2ZdJuhT5fJwNoVNU1prKCny+LNoT2GytmoY8EItILwDMAblTVXQDu\nAzAawEQADUg8Phaak1T1GCTmA7hORE4xrzQ8l1DSrUSkC4ALATxlFEXhfKUQ5vlxQkR+AKANwGNG\nUQOAEao6CcBNAB4Xkd4FNCly7WZhKlKdiYKfLxttaKfQv7FiFnrPgdPyjYhUItGQj6nqswCgqo2q\nGlPVOIAH0BFuKJi9qrrZ+NwK4DnDhsZkSMb43FpouwzOA7BIVRsNG0M/XwaZnp+C2SciVwH4IoCv\nGQIBIzSy3VheiET8e6xhgzm8kxe7smi3Qp6vCgCXAphhsreg58tOGxDib6yYhf59AGNEZKThJV4O\n4IVCHdyIAT4IYIWq3mUqN8e3LwGQzAh4AcDlItJVREYCGIPES6Cg7eopIockl5F4mbfMOH7yrf2V\nAJ432XWF8eZ/CoCdpsfLfJDiaYV9vkxken5eBXCOiPQzwhbnGGWBIiLnAvhvABeq6l5TeZUkZnKD\niIxC4vysM2zbJSJTjN/oFab/JUi7Mm23Ql6vZwFYqartIZlCni8nbUCYv7Fc3i6H/YfE2+rVSNyd\nf1DgY5+ExKPXUgCLjb/zAfwVwIdG+QsABpu2+YFh6yrk+Gbfxa5RSGQ0LAGwPHleAAwAMBfAGgBz\nAPQ3ygWJaR/XGnbX5PGc9QSwHUAfU1nBzxcSN5oGAK1IxD2vyeb8IBEzrzP+vpEnu+qQiNMmf2N/\nMOp+yWjfxQAWAfgX035qkBDetQB+D6NjZMB2ZdxuQV+vdnYZ5X8BcK2lbiHPl5M2hPYbY89YQggp\ncYo5dEMIIcQHFHpCCClxKPSEEFLiUOgJIaTEodATQkiJQ6EnhJASh0JPCCElDoWeEEJKnP8PzhPH\nWT00pWYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.optimizers \n",
    "from keras import backend as K\n",
    "from agent import Agent\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#Env\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(1)  #for comparison\n",
    "num_states = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "#Agent\n",
    "input_dim, output_dim = num_states, num_actions\n",
    "lr, gamma, tau, clipnorm, verbose = 0.001, 0.99, 0.01, True, False\n",
    "agent = Agent(input_dim, output_dim, lr, gamma, tau, clipnorm, verbose)\n",
    "\n",
    "#Train\n",
    "EPISODES = 2000\n",
    "scores = []\n",
    "for e in range(1,EPISODES+1):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, num_states])\n",
    "    reward_sum = 0\n",
    "    done = False\n",
    "    step = 0\n",
    "    while not done:\n",
    "        # env.render()\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "        next_state = np.reshape(next_state, [1, num_states])\n",
    "        agent.remember(state[0], action, reward, next_state[0], done)\n",
    "        state = next_state\n",
    "        step += 1\n",
    "        if step % 1 == 0:\n",
    "            agent.learn()\n",
    "    scores.append(reward_sum)\n",
    "    if e % 50 == 0:\n",
    "        print '(episode, score) = ' + str((e,reward_sum))\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 0 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-942c3fcc5a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mV1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 0 values to unpack"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "from collections import deque\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam \n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, concatenate\n",
    "\n",
    "\n",
    "class Critic:\n",
    "    \n",
    "    \"\"\" Critic for A2C  \"\"\"\n",
    "    \n",
    "    def __init__(self,input_dim, output_dim,lr,gamma,tau, clipnorm, verbose = False):\n",
    "        \n",
    "        #Pars\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lr = lr  #learning rate for optimizer\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.verbose = verbose\n",
    "        self.clipnorm = clipnorm\n",
    "        \n",
    "        #Make models\n",
    "        self.model = self._make_network()\n",
    "        self.target_model = self._make_network()                       \n",
    "        self.target_model.set_weights(self.model.get_weights()) \n",
    "        \n",
    "        #optimizer\n",
    "        self.opt = self.optimizer()\n",
    "        \n",
    "        \n",
    "    def learn(self,S,R,D,V1):\n",
    "        V1 = self.opt([S,R,D,V1])\n",
    "        return V1\n",
    "    \n",
    "    \n",
    "    def _make_network(self):        \n",
    "        S = Input(shape=(self.input_dim,))\n",
    "        x = Dense(128, activation = 'relu')(S)\n",
    "        out = Dense(1, activation = 'linear')(x)\n",
    "        model = Model(inputs = S, outputs = out)\n",
    "        model.compile(loss = 'mse', optimizer = Adam( lr = self.lr, clipnorm = self.clipnorm))\n",
    "        return model\n",
    "       \n",
    " \n",
    "    def optimizer(self):\n",
    "        \n",
    "        \"\"\" \n",
    "            The loss function for the critic is\n",
    "           \n",
    "            L_i = \\sum_{batch}  ( V_i - y_i )^2 \n",
    "            \n",
    "            where,\n",
    "            \n",
    "            y_i = r_i + (1-done) gamma* V_i(s)  for non-terminal \\vec{x'}\n",
    "            r_i = reward to agent i\n",
    "            gamma = discount factor\n",
    "            done = 1 if episode finished, 0 otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        #Placeholders (think of these as inputs)\n",
    "        S_pl = self.model.input\n",
    "        V_pl = self.model.output\n",
    "        R_pl = K.placeholder(name='reward',shape=(None,))\n",
    "        D_pl = K.placeholder(name='done', shape=(None,))\n",
    "        V1_pl = K.placeholder(name='V1',shape=(None,))\n",
    "\n",
    "        #Find yi\n",
    "        V1 = K.sqrt(K.square(V1_pl))\n",
    "        Y = R_pl + (1.0-D_pl)*self.gamma*V1_pl  #1D array\n",
    "        #Y = np.array([ [i] for i in Y])\n",
    "        \n",
    "        #Find loss\n",
    "        loss = K.mean(K.square(V_pl - Y))     #scalar\n",
    "        \n",
    "        #Define optimizer\n",
    "        adam_critic = RMSprop(lr = self.lr, epsilon = 0.1, rho = 0.99)  #arbitray\n",
    "        pars = self.model.trainable_weights\n",
    "        updates = adam_critic.get_updates(params=pars,loss=loss)\n",
    "        \n",
    "        return K.function([S_pl, R_pl, D_pl,V1_pl], [], updates=updates)  \n",
    "\n",
    "    \n",
    "    \n",
    "critic = Critic(input_dim, output_dim,lr,gamma,tau, clipnorm, verbose = False)\n",
    "S,A,R,S1,D = agent.get_batch()\n",
    "D, R = np.array([[x] for x in D]), np.array([[x] for x in R])\n",
    "V1 = critic.model.predict(S1)\n",
    "[out] = critic.learn(S,R,D,V1)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0625844 ],\n",
       "       [-0.00400997],\n",
       "       [ 0.06013154],\n",
       "       [-0.00398179],\n",
       "       [-0.06215289],\n",
       "       [-0.00379891],\n",
       "       [ 0.05594378],\n",
       "       [-0.00509506],\n",
       "       [-0.06334426],\n",
       "       [-0.00536425],\n",
       "       [-0.06347042],\n",
       "       [-0.00653257],\n",
       "       [-0.06363468],\n",
       "       [-0.00741415],\n",
       "       [ 0.04320167],\n",
       "       [ 0.10233249],\n",
       "       [ 0.03926365],\n",
       "       [-0.01085381],\n",
       "       [ 0.03663721],\n",
       "       [-0.01235111],\n",
       "       [ 0.03460442],\n",
       "       [ 0.09667682],\n",
       "       [ 0.0352065 ],\n",
       "       [ 0.09708382],\n",
       "       [ 0.03705866],\n",
       "       [-0.01417046],\n",
       "       [ 0.03740181],\n",
       "       [-0.01367935],\n",
       "       [-0.06499278],\n",
       "       [-0.12066351],\n",
       "       [-0.06460891],\n",
       "       [-0.01387813],\n",
       "       [-0.06484658],\n",
       "       [-0.12029552],\n",
       "       [-0.064547  ],\n",
       "       [-0.01523867],\n",
       "       [ 0.01773329],\n",
       "       [-0.01853967],\n",
       "       [-0.0671837 ],\n",
       "       [-0.0213013 ],\n",
       "       [ 0.00775268],\n",
       "       [ 0.05705822],\n",
       "       [ 0.10912711],\n",
       "       [ 0.05070865],\n",
       "       [ 0.010302  ],\n",
       "       [ 0.04689243],\n",
       "       [ 0.0135592 ],\n",
       "       [ 0.04301232],\n",
       "       [ 0.094636  ],\n",
       "       [ 0.03903016],\n",
       "       [ 0.08888735],\n",
       "       [ 0.14865276],\n",
       "       [ 0.20579612],\n",
       "       [ 0.14732814],\n",
       "       [ 0.09153083],\n",
       "       [ 0.14622563],\n",
       "       [ 0.21046561],\n",
       "       [ 0.14751379],\n",
       "       [ 0.09490442],\n",
       "       [ 0.0314652 ],\n",
       "       [ 0.0958222 ],\n",
       "       [ 0.1503706 ],\n",
       "       [ 0.09911801],\n",
       "       [ 0.15330954],\n",
       "       [ 0.10332756],\n",
       "       [ 0.04305146],\n",
       "       [ 0.00485361],\n",
       "       [ 0.04370073],\n",
       "       [ 0.00546268],\n",
       "       [ 0.04387071],\n",
       "       [ 0.10566918],\n",
       "       [ 0.04626671],\n",
       "       [ 0.1068922 ],\n",
       "       [ 0.04863003],\n",
       "       [ 0.10809125],\n",
       "       [ 0.1638938 ],\n",
       "       [ 0.1111954 ],\n",
       "       [ 0.05399824],\n",
       "       [ 0.00800734],\n",
       "       [-0.02551786],\n",
       "       [ 0.00652307],\n",
       "       [ 0.05381931],\n",
       "       [ 0.10744864],\n",
       "       [ 0.16361085],\n",
       "       [ 0.10881318],\n",
       "       [ 0.16454872],\n",
       "       [ 0.11127259],\n",
       "       [ 0.16577597],\n",
       "       [ 0.11420981],\n",
       "       [ 0.05500472],\n",
       "       [ 0.11491041],\n",
       "       [ 0.16811572],\n",
       "       [ 0.11790913],\n",
       "       [ 0.05799092],\n",
       "       [ 0.11886936],\n",
       "       [ 0.17110386],\n",
       "       [ 0.23087174],\n",
       "       [ 0.17574601],\n",
       "       [ 0.12959298],\n",
       "       [ 0.17991436],\n",
       "       [ 0.24064696],\n",
       "       [ 0.18659228],\n",
       "       [ 0.14561185],\n",
       "       [ 0.19301899],\n",
       "       [ 0.15365103],\n",
       "       [ 0.0849965 ],\n",
       "       [ 0.032075  ],\n",
       "       [-0.00961942],\n",
       "       [ 0.0316341 ],\n",
       "       [ 0.09050578],\n",
       "       [ 0.15931119],\n",
       "       [ 0.20984238],\n",
       "       [ 0.16503854],\n",
       "       [ 0.09751842],\n",
       "       [ 0.16884565]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1 = np.array([[x] for x in D])\n",
    "(1-D1)*V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(input_dim, output_dim, lr, gamma, tau, clipnorm, verbose)\n",
    "state = env.reset()\n",
    "state = np.reshape(state, [1, num_states])\n",
    "reward_sum = 0\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    reward_sum += reward\n",
    "    next_state = np.reshape(next_state, [1, num_states])\n",
    "    agent.remember(state[0], action, reward, next_state[0], done)\n",
    "    state = next_state "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
